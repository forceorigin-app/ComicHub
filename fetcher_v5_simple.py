"""
æ¼«ç”»æŠ“å–æ¨¡å— V5 - ç®€åŒ–ç‰ˆ
åŠŸèƒ½ï¼šç›´æ¥æµ‹è¯•ä¸åŒçš„ TLS è®¾ç½®
"""

import requests
from bs4 import BeautifulSoup
import re
from typing import List, Dict, Optional
import logging
from pathlib import Path
from urllib.parse import urljoin
import time
import json
import ssl
import urllib3

logger = logging.getLogger(__name__)


class ManhuaGuiFetcherV5:
    """æ¼«ç”»é¾ŸæŠ“å–å™¨ V5 (ç®€åŒ–ç‰ˆ - ç›´æ¥ SSL é…ç½®ï¼‰"""

    def __init__(self, base_url: str = "https://m.manhuagui.com"):
        """
        åˆå§‹åŒ–æŠ“å–å™¨
        
        Args:
            base_url: åŸºç¡€ URL
        """
        self.base_url = base_url
        
        # å®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´
        self.default_headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0',
            'Pragma': 'no-cache',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'DNT': '1',
            'Referer': base_url
        }
        
        logger.info(f"æŠ“å–å™¨å·²åˆå§‹åŒ–")

    def test_request_1(self, url: str) -> Optional[str]:
        """
        æµ‹è¯•æ–¹æ³• 1: åŸºç¡€ requestsï¼Œå…³é—­ SSL éªŒè¯
        """
        try:
            logger.info(f"æµ‹è¯• 1: åŸºç¡€ requestsï¼Œå…³é—­ SSL éªŒè¯")
            
            response = requests.get(url, headers=self.default_headers, verify=False, timeout=30)
            
            if response.status_code == 200:
                logger.info(f"âœ… æµ‹è¯• 1 æˆåŠŸ: {response.status_code}")
                return response.text
            else:
                logger.warning(f"âš ï¸ æµ‹è¯• 1 çŠ¶æ€ç : {response.status_code}")
                return None
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯• 1 å¤±è´¥: {e}")
            return None

    def test_request_2(self, url: str) -> Optional[str]:
        """
        æµ‹è¯•æ–¹æ³• 2: ä½¿ç”¨ sessionï¼Œè®¾ç½® SSL ä¸Šä¸‹æ–‡
        """
        try:
            logger.info(f"æµ‹è¯• 2: ä½¿ç”¨ sessionï¼Œè®¾ç½® SSL ä¸Šä¸‹æ–‡")
            
            session = requests.Session()
            session.headers.update(self.default_headers)
            
            # åˆ›å»ºå®½æ¾çš„ SSL ä¸Šä¸‹æ–‡
            ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
            ctx.check_hostname = False
            ctx.verify_mode = ssl.CERT_NONE
            
            # è®¾ç½® TLS 1.0+ æ”¯æŒ
            ctx.minimum_version = ssl.TLSVersion.TLSv1
            ctx.maximum_version = ssl.TLSVersion.MAXIMUM_SUPPORTED
            
            # è®¾ç½®åŠ å¯†å¥—ä»¶
            ctx.set_ciphers('DEFAULT:@SECLEVEL=1')
            
            # åˆ›å»ºé€‚é…å™¨
            adapter = requests.adapters.HTTPAdapter(
                max_retries=3,
                pool_connections=1
            )
            
            # è®¾ç½® SSL ä¸Šä¸‹æ–‡ï¼ˆé€šè¿‡ urllib3ï¼‰
            adapter.poolmanager.connection_pool_kw['https'] = {
                'ssl_context': ctx,
                'assert_hostname': False,
                'cert_reqs': 0  # ssl.CERT_NONE
            }
            
            session.mount('https://', adapter)
            session.mount('http://', requests.adapters.HTTPAdapter(max_retries=3))
            
            response = session.get(url, timeout=30)
            
            if response.status_code == 200:
                logger.info(f"âœ… æµ‹è¯• 2 æˆåŠŸ: {response.status_code}")
                return response.text
            else:
                logger.warning(f"âš ï¸ æµ‹è¯• 2 çŠ¶æ€ç : {response.status_code}")
                return None
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯• 2 å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def test_request_3(self, url: str) -> Optional[str]:
        """
        æµ‹è¯•æ–¹æ³• 3: ä½¿ç”¨ urllib3 ç›´æ¥è¯·æ±‚
        """
        try:
            logger.info(f"æµ‹è¯• 3: ä½¿ç”¨ urllib3 ç›´æ¥è¯·æ±‚")
            
            http = urllib3.PoolManager(
                retries=urllib3.Retry(total=3, backoff_factor=2),
                cert_reqs='CERT_NONE',
                assert_hostname=False
            )
            
            # å‘é€è¯·æ±‚
            response = http.request(
                'GET',
                url,
                headers=self.default_headers,
                timeout=urllib3.Timeout(timeout=30)
            )
            
            if response.status == 200:
                logger.info(f"âœ… æµ‹è¯• 3 æˆåŠŸ: {response.status}")
                return response.data.decode('utf-8')
            else:
                logger.warning(f"âš ï¸ æµ‹è¯• 3 çŠ¶æ€ç : {response.status}")
                return None
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯• 3 å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    print("="*80)
    print("Fetcher V5 ç®€åŒ–ç‰ˆ - å¤šç§ SSL/TLS é…ç½®æµ‹è¯•")
    print("="*80)
    print()
    
    fetcher = ManhuaGuiFetcherV5()
    url = 'https://m.manhuagui.com/comic/1128/'
    
    # æµ‹è¯• 1
    print("æµ‹è¯• 1: åŸºç¡€ requests")
    print("-"*50)
    result1 = fetcher.test_request_1(url)
    if result1:
        print(f"å†…å®¹é•¿åº¦: {len(result1)} å­—ç¬¦")
        print(f"å‰ 200 å­—ç¬¦:")
        print(result1[:200])
        print("\nğŸ‰ æµ‹è¯• 1 æˆåŠŸï¼")
    else:
        print("æµ‹è¯• 1 å¤±è´¥")
    
    print("\n" + "="*80 + "\n")
    
    # æµ‹è¯• 2
    print("æµ‹è¯• 2: Session + SSL ä¸Šä¸‹æ–‡")
    print("-"*50)
    result2 = fetcher.test_request_2(url)
    if result2:
        print(f"å†…å®¹é•¿åº¦: {len(result2)} å­—ç¬¦")
        print(f"å‰ 200 å­—ç¬¦:")
        print(result2[:200])
        print("\nğŸ‰ æµ‹è¯• 2 æˆåŠŸï¼")
    else:
        print("æµ‹è¯• 2 å¤±è´¥")
    
    print("\n" + "="*80 + "\n")
    
    # æµ‹è¯• 3
    print("æµ‹è¯• 3: urllib3 ç›´æ¥è¯·æ±‚")
    print("-"*50)
    result3 = fetcher.test_request_3(url)
    if result3:
        print(f"å†…å®¹é•¿åº¦: {len(result3)} å­—ç¬¦")
        print(f"å‰ 200 å­—ç¬¦:")
        print(result3[:200])
        print("\nğŸ‰ æµ‹è¯• 3 æˆåŠŸï¼")
    else:
        print("æµ‹è¯• 3 å¤±è´¥")
    
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“")
    print("="*80)
    print(f"æµ‹è¯• 1: {'âœ… æˆåŠŸ' if result1 else 'âŒ å¤±è´¥'}")
    print(f"æµ‹è¯• 2: {'âœ… æˆåŠŸ' if result2 else 'âŒ å¤±è´¥'}")
    print(f"æµ‹è¯• 3: {'âœ… æˆåŠŸ' if result3 else 'âŒ å¤±è´¥'}")
